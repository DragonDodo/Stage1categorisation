{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_93/x86_64-slc6-gcc62-opt/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#usual imports\n",
    "import numpy as np\n",
    "import ROOT as r\n",
    "import matplotlib.pyplot as plt\n",
    "from root_numpy import tree2array, testdata, list_branches\n",
    "import pandas as pd\n",
    "import time\n",
    "import xgboost as xg\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import pickle\n",
    "\n",
    "trainFrac = 0.7\n",
    "validFrac = 0.1\n",
    "nClasses = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/sft.cern.ch/lcg/views/LCG_93/x86_64-slc6-gcc62-opt/lib/python2.7/site-packages/root_numpy/_tree.py:385: RuntimeWarning: ignoring duplicate branch named 'nvtx'\n",
      "  cache_size)\n"
     ]
    }
   ],
   "source": [
    "#get trees from files, put them in data frames\n",
    "procFileMap = {'ggh':'ggH.root', 'dipho':'Dipho.root', 'gjet':'GJet.root', 'qcd':'QCD.root' }\n",
    "theProcs = procFileMap.keys()\n",
    "\n",
    "trainDir = '../trainTrees'\n",
    "trainFrames = {}\n",
    "\n",
    "for proc,fn in procFileMap.iteritems():\n",
    "    trainFile   = r.TFile('%s/%s'%(trainDir,fn))\n",
    "    if 'ggh' in proc or 'vbf' in proc: trainTree = trainFile.Get('vbfTagDumper/trees/%s_125_13TeV_VBFDiJet'%proc)\n",
    "    else: trainTree = trainFile.Get('vbfTagDumper/trees/%s_13TeV_VBFDiJet'%proc)\n",
    "    trainFrames[proc] = pd.DataFrame( tree2array(trainTree) )\n",
    "    trainFrames[proc]['proc'] = proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create one total frame\n",
    "trainList = []\n",
    "for proc in theProcs:\n",
    "    trainList.append(trainFrames[proc])\n",
    "trainTotal = pd.concat(trainList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done lower mass cut\n",
      "done upper mass cut\n",
      "done first stage 1 cut\n",
      "done second stage 1 cut\n",
      "done third stage 1 cut\n",
      "done fourth and final stage 1 cut\n"
     ]
    }
   ],
   "source": [
    "#then filter out the events into only those with the phase space we are interested in\n",
    "#trainTotal[trainTotal.diphomva>-0.4]\n",
    "#print 'done dipho mva cut'\n",
    "trainTotal = trainTotal[trainTotal.CMS_hgg_mass>100.]\n",
    "print 'done lower mass cut'\n",
    "trainTotal = trainTotal[trainTotal.CMS_hgg_mass<180.]\n",
    "print 'done upper mass cut'\n",
    "trainTotal = trainTotal[trainTotal.stage1cat>-1.]\n",
    "print 'done first stage 1 cut'\n",
    "trainTotal = trainTotal[trainTotal.stage1cat<12.]\n",
    "print 'done second stage 1 cut'\n",
    "trainTotal = trainTotal[trainTotal.stage1cat!=1]\n",
    "print 'done third stage 1 cut'\n",
    "trainTotal = trainTotal[trainTotal.stage1cat!=2]\n",
    "print 'done fourth and final stage 1 cut'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add diphoton pt as a column\n",
    "def addPt(row):\n",
    "    return row['CMS_hgg_mass']*row['diphoptom']\n",
    "\n",
    "trainTotal['diphopt'] = trainTotal.apply(addPt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>leadmva</th>\n",
       "      <th>subleadmva</th>\n",
       "      <th>leadptom</th>\n",
       "      <th>subleadptom</th>\n",
       "      <th>leadeta</th>\n",
       "      <th>subleadeta</th>\n",
       "      <th>CosPhi</th>\n",
       "      <th>vtxprob</th>\n",
       "      <th>sigmarv</th>\n",
       "      <th>sigmawv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.082500</td>\n",
       "      <td>0.977675</td>\n",
       "      <td>0.253160</td>\n",
       "      <td>0.233796</td>\n",
       "      <td>-0.430246</td>\n",
       "      <td>2.274336</td>\n",
       "      <td>-0.940191</td>\n",
       "      <td>0.337356</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>0.021389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.960867</td>\n",
       "      <td>-0.593394</td>\n",
       "      <td>0.380394</td>\n",
       "      <td>0.242821</td>\n",
       "      <td>-2.301987</td>\n",
       "      <td>-0.135242</td>\n",
       "      <td>-0.990953</td>\n",
       "      <td>0.362964</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.033188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.972219</td>\n",
       "      <td>0.069912</td>\n",
       "      <td>0.279535</td>\n",
       "      <td>0.255804</td>\n",
       "      <td>-0.145196</td>\n",
       "      <td>2.334992</td>\n",
       "      <td>-0.978791</td>\n",
       "      <td>0.151144</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>0.048833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.383183</td>\n",
       "      <td>0.903200</td>\n",
       "      <td>0.257454</td>\n",
       "      <td>0.182706</td>\n",
       "      <td>-1.252758</td>\n",
       "      <td>1.880495</td>\n",
       "      <td>0.866439</td>\n",
       "      <td>0.907744</td>\n",
       "      <td>0.032817</td>\n",
       "      <td>0.032848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.542549</td>\n",
       "      <td>0.183245</td>\n",
       "      <td>0.275836</td>\n",
       "      <td>0.257755</td>\n",
       "      <td>0.700013</td>\n",
       "      <td>-1.824525</td>\n",
       "      <td>-0.749920</td>\n",
       "      <td>0.563038</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>0.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.383437</td>\n",
       "      <td>0.843853</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.168455</td>\n",
       "      <td>-1.332134</td>\n",
       "      <td>1.639903</td>\n",
       "      <td>-0.774641</td>\n",
       "      <td>0.418624</td>\n",
       "      <td>0.025453</td>\n",
       "      <td>0.025458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.890553</td>\n",
       "      <td>0.966199</td>\n",
       "      <td>0.488196</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>1.027406</td>\n",
       "      <td>-0.864465</td>\n",
       "      <td>-0.901668</td>\n",
       "      <td>0.995332</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.009396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.960319</td>\n",
       "      <td>-0.807319</td>\n",
       "      <td>0.215122</td>\n",
       "      <td>0.175469</td>\n",
       "      <td>-2.137508</td>\n",
       "      <td>1.072688</td>\n",
       "      <td>-0.833879</td>\n",
       "      <td>0.953720</td>\n",
       "      <td>0.185446</td>\n",
       "      <td>0.185456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.934239</td>\n",
       "      <td>-0.796070</td>\n",
       "      <td>0.275371</td>\n",
       "      <td>0.127151</td>\n",
       "      <td>-1.057373</td>\n",
       "      <td>2.248209</td>\n",
       "      <td>-0.629555</td>\n",
       "      <td>0.990172</td>\n",
       "      <td>0.018649</td>\n",
       "      <td>0.018779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.915768</td>\n",
       "      <td>0.092856</td>\n",
       "      <td>0.373222</td>\n",
       "      <td>0.286160</td>\n",
       "      <td>-1.172423</td>\n",
       "      <td>0.818604</td>\n",
       "      <td>-0.951794</td>\n",
       "      <td>0.652965</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.023465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.846808</td>\n",
       "      <td>-0.341430</td>\n",
       "      <td>0.332567</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>2.412716</td>\n",
       "      <td>-0.156471</td>\n",
       "      <td>-0.070327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.877994</td>\n",
       "      <td>-0.407735</td>\n",
       "      <td>0.321750</td>\n",
       "      <td>0.159449</td>\n",
       "      <td>2.271053</td>\n",
       "      <td>-0.594953</td>\n",
       "      <td>-0.934247</td>\n",
       "      <td>0.881647</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>0.019870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.899366</td>\n",
       "      <td>-0.531789</td>\n",
       "      <td>0.341878</td>\n",
       "      <td>0.305089</td>\n",
       "      <td>0.280707</td>\n",
       "      <td>-1.732728</td>\n",
       "      <td>-0.982453</td>\n",
       "      <td>0.896221</td>\n",
       "      <td>0.021078</td>\n",
       "      <td>0.023448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.497909</td>\n",
       "      <td>0.957366</td>\n",
       "      <td>0.289478</td>\n",
       "      <td>0.268938</td>\n",
       "      <td>-1.888613</td>\n",
       "      <td>0.490844</td>\n",
       "      <td>-0.976638</td>\n",
       "      <td>0.314494</td>\n",
       "      <td>0.043309</td>\n",
       "      <td>0.043931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.952468</td>\n",
       "      <td>0.782889</td>\n",
       "      <td>0.281852</td>\n",
       "      <td>0.151529</td>\n",
       "      <td>-0.740153</td>\n",
       "      <td>2.330389</td>\n",
       "      <td>-0.907171</td>\n",
       "      <td>0.490553</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>0.019264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.826471</td>\n",
       "      <td>-0.374780</td>\n",
       "      <td>0.262993</td>\n",
       "      <td>0.128044</td>\n",
       "      <td>1.250336</td>\n",
       "      <td>-2.121223</td>\n",
       "      <td>-0.268858</td>\n",
       "      <td>0.991678</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>0.029174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.800541</td>\n",
       "      <td>0.575174</td>\n",
       "      <td>0.211209</td>\n",
       "      <td>0.195117</td>\n",
       "      <td>-2.506711</td>\n",
       "      <td>0.594560</td>\n",
       "      <td>-0.997273</td>\n",
       "      <td>0.763779</td>\n",
       "      <td>0.022657</td>\n",
       "      <td>0.023631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.967536</td>\n",
       "      <td>0.900058</td>\n",
       "      <td>0.314324</td>\n",
       "      <td>0.192195</td>\n",
       "      <td>-0.918459</td>\n",
       "      <td>1.756230</td>\n",
       "      <td>-0.988163</td>\n",
       "      <td>0.352511</td>\n",
       "      <td>0.015979</td>\n",
       "      <td>0.016168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.818329</td>\n",
       "      <td>-0.875330</td>\n",
       "      <td>0.305064</td>\n",
       "      <td>0.151971</td>\n",
       "      <td>-1.107476</td>\n",
       "      <td>1.925812</td>\n",
       "      <td>-0.378180</td>\n",
       "      <td>0.918061</td>\n",
       "      <td>0.069734</td>\n",
       "      <td>0.069756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.840701</td>\n",
       "      <td>0.234076</td>\n",
       "      <td>0.282623</td>\n",
       "      <td>0.159447</td>\n",
       "      <td>0.515908</td>\n",
       "      <td>-2.487000</td>\n",
       "      <td>-0.998635</td>\n",
       "      <td>0.268294</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.023332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.836516</td>\n",
       "      <td>-0.543692</td>\n",
       "      <td>0.427546</td>\n",
       "      <td>0.216015</td>\n",
       "      <td>-1.334252</td>\n",
       "      <td>0.853504</td>\n",
       "      <td>-0.900125</td>\n",
       "      <td>0.881092</td>\n",
       "      <td>0.042949</td>\n",
       "      <td>0.043005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.292497</td>\n",
       "      <td>0.184366</td>\n",
       "      <td>-1.879033</td>\n",
       "      <td>0.931418</td>\n",
       "      <td>-0.933055</td>\n",
       "      <td>0.537974</td>\n",
       "      <td>0.068882</td>\n",
       "      <td>0.068931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.564494</td>\n",
       "      <td>-0.804811</td>\n",
       "      <td>0.395900</td>\n",
       "      <td>0.368263</td>\n",
       "      <td>1.651063</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.727039</td>\n",
       "      <td>0.991205</td>\n",
       "      <td>0.028397</td>\n",
       "      <td>0.032257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.961124</td>\n",
       "      <td>-0.423780</td>\n",
       "      <td>0.293905</td>\n",
       "      <td>0.253002</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>-2.460831</td>\n",
       "      <td>-0.983264</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>0.039192</td>\n",
       "      <td>0.042946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.297273</td>\n",
       "      <td>-0.760243</td>\n",
       "      <td>0.399034</td>\n",
       "      <td>0.274288</td>\n",
       "      <td>0.068707</td>\n",
       "      <td>-1.879875</td>\n",
       "      <td>-0.987677</td>\n",
       "      <td>0.779145</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>0.095009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-0.637201</td>\n",
       "      <td>0.318716</td>\n",
       "      <td>0.378397</td>\n",
       "      <td>0.321853</td>\n",
       "      <td>0.187337</td>\n",
       "      <td>1.987336</td>\n",
       "      <td>-0.998017</td>\n",
       "      <td>0.996218</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.034618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-0.883187</td>\n",
       "      <td>-0.065133</td>\n",
       "      <td>0.279932</td>\n",
       "      <td>0.192063</td>\n",
       "      <td>0.797757</td>\n",
       "      <td>-2.047500</td>\n",
       "      <td>-0.667729</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>0.127724</td>\n",
       "      <td>0.127787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.973867</td>\n",
       "      <td>0.836157</td>\n",
       "      <td>0.415676</td>\n",
       "      <td>0.178369</td>\n",
       "      <td>2.095165</td>\n",
       "      <td>-0.338420</td>\n",
       "      <td>-0.999965</td>\n",
       "      <td>0.829655</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.020037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.605771</td>\n",
       "      <td>0.035181</td>\n",
       "      <td>0.342279</td>\n",
       "      <td>0.189364</td>\n",
       "      <td>0.405341</td>\n",
       "      <td>-2.285067</td>\n",
       "      <td>-0.311437</td>\n",
       "      <td>0.923274</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.024067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.955900</td>\n",
       "      <td>-0.708617</td>\n",
       "      <td>0.260959</td>\n",
       "      <td>0.240411</td>\n",
       "      <td>-2.453154</td>\n",
       "      <td>0.193477</td>\n",
       "      <td>-0.881066</td>\n",
       "      <td>0.489578</td>\n",
       "      <td>0.030468</td>\n",
       "      <td>0.033384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388460</th>\n",
       "      <td>0.696948</td>\n",
       "      <td>0.965413</td>\n",
       "      <td>0.517270</td>\n",
       "      <td>0.472177</td>\n",
       "      <td>1.837558</td>\n",
       "      <td>1.299401</td>\n",
       "      <td>-0.898807</td>\n",
       "      <td>0.456875</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.021175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388461</th>\n",
       "      <td>0.969591</td>\n",
       "      <td>0.937599</td>\n",
       "      <td>0.469453</td>\n",
       "      <td>0.463886</td>\n",
       "      <td>1.202959</td>\n",
       "      <td>0.446464</td>\n",
       "      <td>-0.995925</td>\n",
       "      <td>0.347890</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>0.035820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388462</th>\n",
       "      <td>0.945580</td>\n",
       "      <td>0.952003</td>\n",
       "      <td>0.669959</td>\n",
       "      <td>0.382456</td>\n",
       "      <td>1.223852</td>\n",
       "      <td>1.587477</td>\n",
       "      <td>-0.884530</td>\n",
       "      <td>0.985591</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>0.020386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388463</th>\n",
       "      <td>0.956898</td>\n",
       "      <td>0.753561</td>\n",
       "      <td>0.871289</td>\n",
       "      <td>0.271475</td>\n",
       "      <td>-1.294665</td>\n",
       "      <td>-1.836491</td>\n",
       "      <td>-0.963455</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.026584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388464</th>\n",
       "      <td>0.969089</td>\n",
       "      <td>0.647730</td>\n",
       "      <td>1.322042</td>\n",
       "      <td>0.281304</td>\n",
       "      <td>-1.337661</td>\n",
       "      <td>-1.959016</td>\n",
       "      <td>-0.145131</td>\n",
       "      <td>0.998961</td>\n",
       "      <td>0.016017</td>\n",
       "      <td>0.023011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388467</th>\n",
       "      <td>0.963064</td>\n",
       "      <td>0.878025</td>\n",
       "      <td>0.471693</td>\n",
       "      <td>0.442452</td>\n",
       "      <td>-1.892054</td>\n",
       "      <td>-0.838369</td>\n",
       "      <td>-0.787338</td>\n",
       "      <td>0.952463</td>\n",
       "      <td>0.011534</td>\n",
       "      <td>0.023070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388469</th>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.918756</td>\n",
       "      <td>0.432436</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.356746</td>\n",
       "      <td>-0.807759</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.212041</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.009842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388470</th>\n",
       "      <td>0.510432</td>\n",
       "      <td>0.955279</td>\n",
       "      <td>0.647321</td>\n",
       "      <td>0.420138</td>\n",
       "      <td>1.033233</td>\n",
       "      <td>1.125614</td>\n",
       "      <td>-0.834206</td>\n",
       "      <td>0.751505</td>\n",
       "      <td>0.013440</td>\n",
       "      <td>0.022894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388473</th>\n",
       "      <td>0.954834</td>\n",
       "      <td>0.952293</td>\n",
       "      <td>0.537047</td>\n",
       "      <td>0.361846</td>\n",
       "      <td>-1.006666</td>\n",
       "      <td>0.374772</td>\n",
       "      <td>-0.457048</td>\n",
       "      <td>0.665525</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.011831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388475</th>\n",
       "      <td>0.684362</td>\n",
       "      <td>0.865562</td>\n",
       "      <td>0.651710</td>\n",
       "      <td>0.371709</td>\n",
       "      <td>-0.343752</td>\n",
       "      <td>-0.780378</td>\n",
       "      <td>-0.967165</td>\n",
       "      <td>0.917348</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.017746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388478</th>\n",
       "      <td>0.966363</td>\n",
       "      <td>0.753259</td>\n",
       "      <td>0.545829</td>\n",
       "      <td>0.320209</td>\n",
       "      <td>-2.205577</td>\n",
       "      <td>-0.490225</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.987480</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>0.030125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388479</th>\n",
       "      <td>0.960017</td>\n",
       "      <td>0.911545</td>\n",
       "      <td>0.306151</td>\n",
       "      <td>0.151165</td>\n",
       "      <td>0.840204</td>\n",
       "      <td>-2.169069</td>\n",
       "      <td>-0.642976</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.017413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388480</th>\n",
       "      <td>0.055972</td>\n",
       "      <td>0.965884</td>\n",
       "      <td>0.374107</td>\n",
       "      <td>0.258443</td>\n",
       "      <td>-0.752740</td>\n",
       "      <td>1.359669</td>\n",
       "      <td>-0.976876</td>\n",
       "      <td>0.478690</td>\n",
       "      <td>0.101495</td>\n",
       "      <td>0.101541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388481</th>\n",
       "      <td>0.964881</td>\n",
       "      <td>0.966049</td>\n",
       "      <td>0.657539</td>\n",
       "      <td>0.308496</td>\n",
       "      <td>-0.352704</td>\n",
       "      <td>0.580468</td>\n",
       "      <td>-0.996963</td>\n",
       "      <td>0.980308</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.008473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388483</th>\n",
       "      <td>0.897840</td>\n",
       "      <td>0.845199</td>\n",
       "      <td>0.433191</td>\n",
       "      <td>0.388063</td>\n",
       "      <td>0.086051</td>\n",
       "      <td>-1.216195</td>\n",
       "      <td>-0.999585</td>\n",
       "      <td>0.193140</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.017186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388488</th>\n",
       "      <td>0.947860</td>\n",
       "      <td>0.852282</td>\n",
       "      <td>0.763117</td>\n",
       "      <td>0.185791</td>\n",
       "      <td>-0.373827</td>\n",
       "      <td>1.223767</td>\n",
       "      <td>-0.954823</td>\n",
       "      <td>0.969118</td>\n",
       "      <td>0.010409</td>\n",
       "      <td>0.012690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388490</th>\n",
       "      <td>0.227502</td>\n",
       "      <td>0.722930</td>\n",
       "      <td>0.585630</td>\n",
       "      <td>0.393466</td>\n",
       "      <td>-0.987379</td>\n",
       "      <td>-0.048155</td>\n",
       "      <td>-0.695433</td>\n",
       "      <td>0.786537</td>\n",
       "      <td>0.056677</td>\n",
       "      <td>0.058263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388491</th>\n",
       "      <td>0.913856</td>\n",
       "      <td>0.920891</td>\n",
       "      <td>0.817776</td>\n",
       "      <td>0.321858</td>\n",
       "      <td>0.705869</td>\n",
       "      <td>0.801260</td>\n",
       "      <td>-0.895090</td>\n",
       "      <td>1.000008</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.020479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388492</th>\n",
       "      <td>0.915656</td>\n",
       "      <td>0.175991</td>\n",
       "      <td>0.546314</td>\n",
       "      <td>0.372536</td>\n",
       "      <td>-0.432690</td>\n",
       "      <td>0.922700</td>\n",
       "      <td>-0.388686</td>\n",
       "      <td>0.730609</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.010646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388493</th>\n",
       "      <td>0.634847</td>\n",
       "      <td>0.683893</td>\n",
       "      <td>0.968723</td>\n",
       "      <td>0.218249</td>\n",
       "      <td>0.834954</td>\n",
       "      <td>1.665637</td>\n",
       "      <td>-0.999612</td>\n",
       "      <td>0.997489</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>0.027248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388494</th>\n",
       "      <td>0.929072</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.651226</td>\n",
       "      <td>0.279667</td>\n",
       "      <td>-2.032649</td>\n",
       "      <td>-0.874922</td>\n",
       "      <td>-0.996902</td>\n",
       "      <td>0.999037</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.027843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388496</th>\n",
       "      <td>0.975273</td>\n",
       "      <td>0.904916</td>\n",
       "      <td>0.535902</td>\n",
       "      <td>0.280215</td>\n",
       "      <td>-2.102396</td>\n",
       "      <td>-0.572441</td>\n",
       "      <td>-0.912355</td>\n",
       "      <td>0.993879</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.026484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388502</th>\n",
       "      <td>0.981066</td>\n",
       "      <td>0.916156</td>\n",
       "      <td>0.702655</td>\n",
       "      <td>0.527223</td>\n",
       "      <td>1.075448</td>\n",
       "      <td>1.676386</td>\n",
       "      <td>-0.163627</td>\n",
       "      <td>0.999654</td>\n",
       "      <td>0.013345</td>\n",
       "      <td>0.022507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388504</th>\n",
       "      <td>0.556911</td>\n",
       "      <td>-0.710051</td>\n",
       "      <td>0.455127</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>0.039745</td>\n",
       "      <td>-1.934159</td>\n",
       "      <td>-0.266336</td>\n",
       "      <td>0.668737</td>\n",
       "      <td>0.017703</td>\n",
       "      <td>0.024257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388505</th>\n",
       "      <td>0.544682</td>\n",
       "      <td>0.843911</td>\n",
       "      <td>0.180713</td>\n",
       "      <td>0.160188</td>\n",
       "      <td>-1.080443</td>\n",
       "      <td>2.401222</td>\n",
       "      <td>-0.999960</td>\n",
       "      <td>0.520317</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.022266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388506</th>\n",
       "      <td>0.983397</td>\n",
       "      <td>0.543037</td>\n",
       "      <td>0.220232</td>\n",
       "      <td>0.220114</td>\n",
       "      <td>-2.389891</td>\n",
       "      <td>0.531988</td>\n",
       "      <td>-0.999369</td>\n",
       "      <td>0.574316</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.018643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388507</th>\n",
       "      <td>0.875089</td>\n",
       "      <td>0.927766</td>\n",
       "      <td>0.423545</td>\n",
       "      <td>0.214721</td>\n",
       "      <td>-2.325306</td>\n",
       "      <td>-0.128916</td>\n",
       "      <td>-0.946049</td>\n",
       "      <td>0.996790</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>0.027171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388508</th>\n",
       "      <td>0.951418</td>\n",
       "      <td>0.951466</td>\n",
       "      <td>0.538745</td>\n",
       "      <td>0.474209</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.403926</td>\n",
       "      <td>-0.812407</td>\n",
       "      <td>0.520141</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.019084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388509</th>\n",
       "      <td>0.505487</td>\n",
       "      <td>0.832830</td>\n",
       "      <td>0.328613</td>\n",
       "      <td>0.294543</td>\n",
       "      <td>-1.405181</td>\n",
       "      <td>1.073238</td>\n",
       "      <td>0.837351</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.057927</td>\n",
       "      <td>0.057957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388512</th>\n",
       "      <td>0.944499</td>\n",
       "      <td>0.943495</td>\n",
       "      <td>0.539113</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>-0.246407</td>\n",
       "      <td>1.413772</td>\n",
       "      <td>-0.500500</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>0.014077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5232865 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          leadmva  subleadmva  leadptom  subleadptom   leadeta  subleadeta  \\\n",
       "1       -0.082500    0.977675  0.253160     0.233796 -0.430246    2.274336   \n",
       "5        0.960867   -0.593394  0.380394     0.242821 -2.301987   -0.135242   \n",
       "9        0.972219    0.069912  0.279535     0.255804 -0.145196    2.334992   \n",
       "11       0.383183    0.903200  0.257454     0.182706 -1.252758    1.880495   \n",
       "15      -0.542549    0.183245  0.275836     0.257755  0.700013   -1.824525   \n",
       "17       0.383437    0.843853  0.280913     0.168455 -1.332134    1.639903   \n",
       "18       0.890553    0.966199  0.488196     0.238573  1.027406   -0.864465   \n",
       "19       0.960319   -0.807319  0.215122     0.175469 -2.137508    1.072688   \n",
       "21       0.934239   -0.796070  0.275371     0.127151 -1.057373    2.248209   \n",
       "23       0.915768    0.092856  0.373222     0.286160 -1.172423    0.818604   \n",
       "24       0.846808   -0.341430  0.332567     0.226553  2.412716   -0.156471   \n",
       "26       0.877994   -0.407735  0.321750     0.159449  2.271053   -0.594953   \n",
       "27       0.899366   -0.531789  0.341878     0.305089  0.280707   -1.732728   \n",
       "31       0.497909    0.957366  0.289478     0.268938 -1.888613    0.490844   \n",
       "32       0.952468    0.782889  0.281852     0.151529 -0.740153    2.330389   \n",
       "34       0.826471   -0.374780  0.262993     0.128044  1.250336   -2.121223   \n",
       "41       0.800541    0.575174  0.211209     0.195117 -2.506711    0.594560   \n",
       "42       0.967536    0.900058  0.314324     0.192195 -0.918459    1.756230   \n",
       "44       0.818329   -0.875330  0.305064     0.151971 -1.107476    1.925812   \n",
       "46       0.840701    0.234076  0.282623     0.159447  0.515908   -2.487000   \n",
       "56       0.836516   -0.543692  0.427546     0.216015 -1.334252    0.853504   \n",
       "57       0.942500    0.008049  0.292497     0.184366 -1.879033    0.931418   \n",
       "62       0.564494   -0.804811  0.395900     0.368263  1.651063   -0.000098   \n",
       "68       0.961124   -0.423780  0.293905     0.253002 -0.027739   -2.460831   \n",
       "76       0.297273   -0.760243  0.399034     0.274288  0.068707   -1.879875   \n",
       "81      -0.637201    0.318716  0.378397     0.321853  0.187337    1.987336   \n",
       "89      -0.883187   -0.065133  0.279932     0.192063  0.797757   -2.047500   \n",
       "90       0.973867    0.836157  0.415676     0.178369  2.095165   -0.338420   \n",
       "94       0.605771    0.035181  0.342279     0.189364  0.405341   -2.285067   \n",
       "97       0.955900   -0.708617  0.260959     0.240411 -2.453154    0.193477   \n",
       "...           ...         ...       ...          ...       ...         ...   \n",
       "5388460  0.696948    0.965413  0.517270     0.472177  1.837558    1.299401   \n",
       "5388461  0.969591    0.937599  0.469453     0.463886  1.202959    0.446464   \n",
       "5388462  0.945580    0.952003  0.669959     0.382456  1.223852    1.587477   \n",
       "5388463  0.956898    0.753561  0.871289     0.271475 -1.294665   -1.836491   \n",
       "5388464  0.969089    0.647730  1.322042     0.281304 -1.337661   -1.959016   \n",
       "5388467  0.963064    0.878025  0.471693     0.442452 -1.892054   -0.838369   \n",
       "5388469  0.975253    0.918756  0.432436     0.419200  0.356746   -0.807759   \n",
       "5388470  0.510432    0.955279  0.647321     0.420138  1.033233    1.125614   \n",
       "5388473  0.954834    0.952293  0.537047     0.361846 -1.006666    0.374772   \n",
       "5388475  0.684362    0.865562  0.651710     0.371709 -0.343752   -0.780378   \n",
       "5388478  0.966363    0.753259  0.545829     0.320209 -2.205577   -0.490225   \n",
       "5388479  0.960017    0.911545  0.306151     0.151165  0.840204   -2.169069   \n",
       "5388480  0.055972    0.965884  0.374107     0.258443 -0.752740    1.359669   \n",
       "5388481  0.964881    0.966049  0.657539     0.308496 -0.352704    0.580468   \n",
       "5388483  0.897840    0.845199  0.433191     0.388063  0.086051   -1.216195   \n",
       "5388488  0.947860    0.852282  0.763117     0.185791 -0.373827    1.223767   \n",
       "5388490  0.227502    0.722930  0.585630     0.393466 -0.987379   -0.048155   \n",
       "5388491  0.913856    0.920891  0.817776     0.321858  0.705869    0.801260   \n",
       "5388492  0.915656    0.175991  0.546314     0.372536 -0.432690    0.922700   \n",
       "5388493  0.634847    0.683893  0.968723     0.218249  0.834954    1.665637   \n",
       "5388494  0.929072    0.938310  0.651226     0.279667 -2.032649   -0.874922   \n",
       "5388496  0.975273    0.904916  0.535902     0.280215 -2.102396   -0.572441   \n",
       "5388502  0.981066    0.916156  0.702655     0.527223  1.075448    1.676386   \n",
       "5388504  0.556911   -0.710051  0.455127     0.279174  0.039745   -1.934159   \n",
       "5388505  0.544682    0.843911  0.180713     0.160188 -1.080443    2.401222   \n",
       "5388506  0.983397    0.543037  0.220232     0.220114 -2.389891    0.531988   \n",
       "5388507  0.875089    0.927766  0.423545     0.214721 -2.325306   -0.128916   \n",
       "5388508  0.951418    0.951466  0.538745     0.474209  0.935622    0.403926   \n",
       "5388509  0.505487    0.832830  0.328613     0.294543 -1.405181    1.073238   \n",
       "5388512  0.944499    0.943495  0.539113     0.287521 -0.246407    1.413772   \n",
       "\n",
       "           CosPhi   vtxprob   sigmarv   sigmawv  \n",
       "1       -0.940191  0.337356  0.019388  0.021389  \n",
       "5       -0.990953  0.362964  0.027290  0.033188  \n",
       "9       -0.978791  0.151144  0.046733  0.048833  \n",
       "11       0.866439  0.907744  0.032817  0.032848  \n",
       "15      -0.749920  0.563038  0.024763  0.025208  \n",
       "17      -0.774641  0.418624  0.025453  0.025458  \n",
       "18      -0.901668  0.995332  0.009343  0.009396  \n",
       "19      -0.833879  0.953720  0.185446  0.185456  \n",
       "21      -0.629555  0.990172  0.018649  0.018779  \n",
       "23      -0.951794  0.652965  0.023384  0.023465  \n",
       "24      -0.070327  1.000000  0.018601  0.024100  \n",
       "26      -0.934247  0.881647  0.018768  0.019870  \n",
       "27      -0.982453  0.896221  0.021078  0.023448  \n",
       "31      -0.976638  0.314494  0.043309  0.043931  \n",
       "32      -0.907171  0.490553  0.018672  0.019264  \n",
       "34      -0.268858  0.991678  0.029146  0.029174  \n",
       "41      -0.997273  0.763779  0.022657  0.023631  \n",
       "42      -0.988163  0.352511  0.015979  0.016168  \n",
       "44      -0.378180  0.918061  0.069734  0.069756  \n",
       "46      -0.998635  0.268294  0.021985  0.023332  \n",
       "56      -0.900125  0.881092  0.042949  0.043005  \n",
       "57      -0.933055  0.537974  0.068882  0.068931  \n",
       "62      -0.727039  0.991205  0.028397  0.032257  \n",
       "68      -0.983264  0.238281  0.039192  0.042946  \n",
       "76      -0.987677  0.779145  0.093914  0.095009  \n",
       "81      -0.998017  0.996218  0.029189  0.034618  \n",
       "89      -0.667729  0.999489  0.127724  0.127787  \n",
       "90      -0.999965  0.829655  0.017284  0.020037  \n",
       "94      -0.311437  0.923274  0.021837  0.024067  \n",
       "97      -0.881066  0.489578  0.030468  0.033384  \n",
       "...           ...       ...       ...       ...  \n",
       "5388460 -0.898807  0.456875  0.013699  0.021175  \n",
       "5388461 -0.995925  0.347890  0.030806  0.035820  \n",
       "5388462 -0.884530  0.985591  0.012573  0.020386  \n",
       "5388463 -0.963455  0.999988  0.020969  0.026584  \n",
       "5388464 -0.145131  0.998961  0.016017  0.023011  \n",
       "5388467 -0.787338  0.952463  0.011534  0.023070  \n",
       "5388469 -1.000000  0.212041  0.008319  0.009842  \n",
       "5388470 -0.834206  0.751505  0.013440  0.022894  \n",
       "5388473 -0.457048  0.665525  0.009586  0.011831  \n",
       "5388475 -0.967165  0.917348  0.007799  0.017746  \n",
       "5388478  0.008514  0.987480  0.018431  0.030125  \n",
       "5388479 -0.642976  0.999176  0.017003  0.017413  \n",
       "5388480 -0.976876  0.478690  0.101495  0.101541  \n",
       "5388481 -0.996963  0.980308  0.007881  0.008473  \n",
       "5388483 -0.999585  0.193140  0.012431  0.017186  \n",
       "5388488 -0.954823  0.969118  0.010409  0.012690  \n",
       "5388490 -0.695433  0.786537  0.056677  0.058263  \n",
       "5388491 -0.895090  1.000008  0.008627  0.020479  \n",
       "5388492 -0.388686  0.730609  0.009108  0.010646  \n",
       "5388493 -0.999612  0.997489  0.019589  0.027248  \n",
       "5388494 -0.996902  0.999037  0.019174  0.027843  \n",
       "5388496 -0.912355  0.993879  0.015357  0.026484  \n",
       "5388502 -0.163627  0.999654  0.013345  0.022507  \n",
       "5388504 -0.266336  0.668737  0.017703  0.024257  \n",
       "5388505 -0.999960  0.520317  0.022171  0.022266  \n",
       "5388506 -0.999369  0.574316  0.017080  0.018643  \n",
       "5388507 -0.946049  0.996790  0.019530  0.027171  \n",
       "5388508 -0.812407  0.520141  0.007906  0.019084  \n",
       "5388509  0.837351  0.998700  0.057927  0.057957  \n",
       "5388512 -0.500500  0.999900  0.009046  0.014077  \n",
       "\n",
       "[5232865 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the different sets of variables used\n",
    "diphoVars  = ['leadmva','subleadmva','leadptom','subleadptom',\n",
    "              'leadeta','subleadeta',\n",
    "              'CosPhi','vtxprob','sigmarv','sigmawv']\n",
    "classVars  = ['n_rec_jets','dijet_Mjj','diphopt',\n",
    "              'dijet_leadEta','dijet_subleadEta','dijet_subsubleadEta',\n",
    "              #'dijet_LeadJPt','dijet_SubJPt','dijet_SubsubJPt',\n",
    "              'dijet_LeadJPt','dijet_SubJPt',\n",
    "              'dijet_leadPUMVA','dijet_subleadPUMVA','dijet_subsubleadPUMVA',\n",
    "              'dijet_leadDeltaPhi','dijet_subleadDeltaPhi','dijet_subsubleadDeltaPhi',\n",
    "              'dijet_leadDeltaEta','dijet_subleadDeltaEta','dijet_subsubleadDeltaEta']\n",
    "trainTotal[diphoVars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column corresponding to truth bin\n",
    "def truthDipho(row):\n",
    "    if not row['stage1cat']==0: return 1\n",
    "    else: return 0\n",
    "\n",
    "trainTotal['truthDipho'] = trainTotal.apply(truthDipho,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column corresponding to truth bin\n",
    "def truthClass(row):\n",
    "    if not row['stage1cat']==0: return int(row['stage1cat']-3)\n",
    "    else: return 0\n",
    "\n",
    "trainTotal['truthClass'] = trainTotal.apply(truthClass,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column corresponding to reco bin\n",
    "def reco(row):\n",
    "    if row['n_rec_jets']==0: return 0\n",
    "    elif row['n_rec_jets']==1:\n",
    "        if row['diphopt'] < 60: return 1\n",
    "        elif row['diphopt'] < 120: return 2\n",
    "        elif row['diphopt'] < 200: return 3\n",
    "        else: return 4\n",
    "    else:\n",
    "        if row['diphopt'] < 60: return 5\n",
    "        elif row['diphopt'] < 120: return 6\n",
    "        elif row['diphopt'] < 200: return 7\n",
    "        else: return 8\n",
    "\n",
    "\n",
    "trainTotal['reco'] = trainTotal.apply(reco,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column with full weights for testing\n",
    "def fullWeight(row):\n",
    "    if row['proc'] == 'dipho': return 3. * row['weight'] #only using 1/3 of the diphoton sample\n",
    "    else: return row['weight']\n",
    "trainTotal['fullWeight'] = trainTotal.apply(fullWeight,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column with *normalised weights for training only*\n",
    "weightFactors = [1., 0.0002994, 0.0000757, 0.0000530, 0.0000099, 0.0000029, 0.0000154, 0.0000235, 0.0000165, 0.0000104]\n",
    "def normWeight(row):\n",
    "    weight = row['weight']\n",
    "    if row['proc'] == 'dipho': \n",
    "        weight *= 3. / weightFactors[ int(row['truthClass']) ] #only using 1/3 of the diphoton sample\n",
    "    elif row['proc'] == 'qcd': \n",
    "        weight *= 0.04 / weightFactors[ int(row['truthClass']) ] #reduce because too large by default\n",
    "    else: \n",
    "        weight *= 1. / weightFactors[ int(row['truthClass']) ] #otherwise just reweight by xs\n",
    "    #now account for the resolution\n",
    "    if row['sigmarv']>0. and row['sigmawv']>0.:\n",
    "        weight *= ( (row['vtxprob']/row['sigmarv']) + ((1.-row['vtxprob'])/row['sigmawv']) )\n",
    "    weight = abs(weight)\n",
    "    return weight\n",
    "trainTotal['normedWeight'] = trainTotal.apply(normWeight,axis=1)\n",
    "\n",
    "#elif row['truth'] == 1: return 5. * row['weight'] / weightFactors[ int(row['truth']) ] #optional ad-hoc factor\n",
    "#trainTotal['normedWeight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all necessary variables added - good idea to save at this point! \n",
    "trainTotal.to_pickle('trainTotal.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the various datasets\n",
    "#FIXME need to fix this to *drop* the background from the multi-class training\n",
    "allC = trainTotal[classVars].values #multi-classifier input variables\n",
    "allD = trainTotal[diphoVars].values #diphoton BDT input variables\n",
    "allY = trainTotal['truthClass'].values #signal or background\n",
    "allZ = trainTotal['truthDipho'].values #truth/target values (i.e. the gen-level Stage 1 bins)\n",
    "allFW = trainTotal['fullWeight'].values #weights corresponding to number of events\n",
    "allNW = trainTotal['normedWeight'].values #normalised weights for training - can be played with\n",
    "allR = trainTotal['reco'].values\n",
    "allM = trainTotal['CMS_hgg_mass'].values\n",
    "shuffle = np.random.permutation(allC.shape[0])\n",
    "allC = allC[shuffle]\n",
    "allD = allD[shuffle]\n",
    "allY = allY[shuffle]\n",
    "allZ = allZ[shuffle]\n",
    "allFW = allFW[shuffle]\n",
    "allNW = allNW[shuffle]\n",
    "allR = allR[shuffle]\n",
    "allM = allM[shuffle]\n",
    "trainLimit = int(allC.shape[0]*trainFrac)\n",
    "validLimit = int(allC.shape[0]*(trainFrac+validFrac))\n",
    "trainC, validC, testC = np.split( allC, [trainLimit,validLimit] )\n",
    "trainD, validD, testD = np.split( allD, [trainLimit,validLimit] )\n",
    "trainY, validY, testY = np.split( allY, [trainLimit,validLimit] )\n",
    "trainZ, validZ, testZ = np.split( allZ, [trainLimit,validLimit] )\n",
    "trainFW, validFW, testFW = np.split( allFW, [trainLimit,validLimit] )\n",
    "trainNW, validNW, testNW = np.split( allNW, [trainLimit,validLimit] )\n",
    "trainR, validR, testR = np.split( allR, [trainLimit,validLimit] )\n",
    "trainM, validM, testM = np.split( allM, [trainLimit,validLimit] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18:47:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:48:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:48:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:48:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:48:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:48:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:49:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:49:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:49:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:49:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:49:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:49:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:50:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:50:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:50:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:50:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:50:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:50:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:51:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:51:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:51:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:51:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:51:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:51:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:52:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:52:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:52:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:52:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:52:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:52:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:53:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:53:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:53:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:53:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:53:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:54:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:55:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:55:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:55:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:55:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:55:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:55:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:56:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:56:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:56:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:56:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:56:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:56:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:57:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:57:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:57:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:57:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:57:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:57:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:58:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:58:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:58:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:58:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:58:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:58:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:59:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:59:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:59:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:59:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:59:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18:59:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:00:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:00:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:00:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:00:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:00:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:00:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:01:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:01:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:01:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:01:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:01:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:01:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:02:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:02:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:02:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:02:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:02:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    }
   ],
   "source": [
    "#build the multi-classifier\n",
    "trainingClass = xg.DMatrix(trainC, label=trainY, weight=trainNW, feature_names=classVars)\n",
    "testingClass  = xg.DMatrix(testC, label=testY, weight=testFW, feature_names=classVars)\n",
    "paramClass = {}\n",
    "paramClass['objective'] = 'multi:softprob'\n",
    "paramClass['num_class'] = nClasses\n",
    "classModel = xg.train(paramClass, trainingClass)\n",
    "\n",
    "#save it\n",
    "classModel.save_model('classModel.model')\n",
    "pickle.dump(classModel, open(\"classModel.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:09:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:09:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:10:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:10:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:10:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:10:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:10:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:10:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:11:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19:11:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 126 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    }
   ],
   "source": [
    "#build the background discrimination BDT\n",
    "trainingDipho = xg.DMatrix(trainD, label=trainZ, weight=trainNW, feature_names=diphoVars)\n",
    "testingDipho  = xg.DMatrix(testD, label=testZ, weight=testFW, feature_names=diphoVars)\n",
    "paramDipho = {}\n",
    "paramDipho['objective'] = 'binary:logistic'\n",
    "diphoModel = xg.train(paramDipho, trainingDipho)\n",
    "\n",
    "#save it\n",
    "diphoModel.save_model('diphoModel.model')\n",
    "pickle.dump(diphoModel, open(\"diphoModel.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 ..., 0 0 0]\n",
      "[5 2 6 ..., 5 2 7]\n",
      "\n",
      "[0 1 1 ..., 0 0 0]\n",
      "[ 0.2160857   0.92750895  0.97573304 ...,  0.49987105  0.96475571\n",
      "  0.9716385 ]\n",
      "0.814326669778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.00160566,  0.00161531, ...,  0.99995486,\n",
       "         0.9999552 ,  1.        ]),\n",
       " array([ 0.        ,  0.02913263,  0.02978483, ...,  1.        ,\n",
       "         1.        ,  1.        ]),\n",
       " array([  1.97736502e+00,   9.77364957e-01,   9.77251410e-01, ...,\n",
       "          5.88232477e-04,   5.80993074e-04,   3.18984268e-04], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get predicted values\n",
    "predProbClass = classModel.predict(testingClass).reshape(testY.shape[0],nClasses) #FIXME: not sure if this is right\n",
    "predY = np.argmax(predProbClass, axis=1)\n",
    "print testY\n",
    "print predY\n",
    "print\n",
    "\n",
    "predProbDipho = diphoModel.predict(testingDipho)\n",
    "print testZ\n",
    "print predProbDipho\n",
    "print roc_auc_score(testZ, predProbDipho, sample_weight=testFW)\n",
    "roc_curve(testZ, predProbDipho, sample_weight=testFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup 2D hists\n",
    "truthHist = r.TH1F('truthHist','truthHist',nClasses,-0.5,nClasses-0.5)\n",
    "predHist  = r.TH1F('predHist','predHist',nClasses,-0.5,nClasses-0.5)\n",
    "rightHist = r.TH1F('rightHist','rightHist',nClasses,-0.5,nClasses-0.5)\n",
    "wrongHist = r.TH1F('wrongHist','wrongHist',nClasses,-0.5,nClasses-0.5)\n",
    "for true,guess,w in zip(testY,pred,testFW):\n",
    "    truthHist.Fill(true,w)\n",
    "    predHist.Fill(guess,w)\n",
    "    if true==guess: rightHist.Fill(true,w)\n",
    "    else: wrongHist.Fill(true,w)\n",
    "firstBinVal = -1.\n",
    "for iBin in range(1,truthHist.GetNbinsX()+1):\n",
    "    if iBin==1: firstBinVal = truthHist.GetBinContent(iBin)\n",
    "    ratio = float(truthHist.GetBinContent(iBin)) / firstBinVal\n",
    "    print 'ratio for bin %g is %1.7f'%(iBin,ratio)\n",
    "wrongHist.Add(rightHist)\n",
    "rightHist.Divide(wrongHist)\n",
    "effHist = r.TH1F\n",
    "r.gStyle.SetOptStat(0)\n",
    "canv = r.TCanvas()\n",
    "canv.cd()\n",
    "truthHist.GetYaxis().SetRangeUser(0.,6.)\n",
    "truthHist.Draw('hist')\n",
    "canv.Print('truthHist.pdf')\n",
    "predHist.GetYaxis().SetRangeUser(0.,6.)\n",
    "predHist.Draw('hist')\n",
    "canv.Print('predHist.pdf')\n",
    "rightHist.GetYaxis().SetRangeUser(0.,1.)\n",
    "rightHist.Draw('hist')\n",
    "canv.Print('efficiencyHist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate weights for the 2D hists    \n",
    "sumwProcCatMapReco = {}\n",
    "sumwProcCatMapPred = {}\n",
    "sumwProcMap = {}\n",
    "for iProc in range(1, nClasses):\n",
    "    sumwProcMap[iProc] = np.sum(testFW*(testY==iProc))\n",
    "    for jProc in range(nClasses):\n",
    "        sumwProcCatMapPred[(iProc,jProc)] = np.sum(testFW*(testY==iProc)*(pred==jProc))\n",
    "        sumwProcCatMapReco[(iProc,jProc)] = np.sum(testFW*(testY==iProc)*(testR==jProc))\n",
    "sumwCatMapReco = {}\n",
    "sumwCatMapPred = {}\n",
    "for iProc in range(1, nClasses):\n",
    "    #sumwCatMapPred[iProc] = np.sum(testFW*(pred==iProc))\n",
    "    #sumwCatMapReco[iProc] = np.sum(testFW*(testR==iProc)\n",
    "    sumwCatMapPred[iProc] = np.sum(testFW*(pred==iProc)*(testY!=0)) #don't count bkg here\n",
    "    sumwCatMapReco[iProc] = np.sum(testFW*(testR==iProc)*(testY!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the 2D hists\n",
    "nBinsX=nClasses\n",
    "nBinsY=nClasses\n",
    "procHistReco = r.TH2F('procHistReco','procHistReco', nBinsX, -0.5, nBinsX-0.5, nBinsY, -0.5, nBinsY-0.5)\n",
    "procHistReco.SetTitle('')\n",
    "procHistPred = r.TH2F('procHistPred','procHistPred', nBinsX, -0.5, nBinsX-0.5, nBinsY, -0.5, nBinsY-0.5)\n",
    "procHistPred.SetTitle('')\n",
    "catHistReco  = r.TH2F('catHistReco','catHistReco', nBinsX, -0.5, nBinsX-0.5, nBinsY, -0.5, nBinsY-0.5)\n",
    "catHistReco.SetTitle('')\n",
    "catHistPred  = r.TH2F('catHistPred','catHistPred', nBinsX, -0.5, nBinsX-0.5, nBinsY, -0.5, nBinsY-0.5)\n",
    "catHistPred.SetTitle('')\n",
    "for iProc in range(1, nClasses):\n",
    "    for jProc in range(1, nClasses):\n",
    "        procWeightReco = 100. * sumwProcCatMapReco[(iProc,jProc)] / sumwProcMap[iProc]\n",
    "        procWeightPred = 100. * sumwProcCatMapPred[(iProc,jProc)] / sumwProcMap[iProc]\n",
    "        catWeightReco  = 100. * sumwProcCatMapReco[(iProc,jProc)] / sumwCatMapReco[jProc]\n",
    "        catWeightPred  = 100. * sumwProcCatMapPred[(iProc,jProc)] / sumwCatMapPred[jProc]\n",
    "        \n",
    "        procHistReco.Fill(iProc, jProc, procWeightReco)\n",
    "        procHistPred.Fill(iProc, jProc, procWeightPred)\n",
    "        catHistReco.Fill(iProc, jProc, catWeightReco)\n",
    "        catHistPred.Fill(iProc, jProc, catWeightPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the 2D hists\n",
    "def prettyHist(hist):\n",
    "    hist.SetStats(0)\n",
    "    hist.GetXaxis().SetTitle('Process')\n",
    "    hist.GetXaxis().SetTickLength(0.)\n",
    "    hist.GetYaxis().SetTitle('Category')\n",
    "    hist.GetYaxis().SetTitleOffset(1.5)\n",
    "    hist.GetYaxis().SetTickLength(0.)\n",
    "    hist.SetMinimum(-0.00001)\n",
    "    hist.SetMaximum(100.)\n",
    "    \n",
    "canv = r.TCanvas()\n",
    "r.gStyle.SetPaintTextFormat('2.0f')\n",
    "prettyHist(procHistReco)\n",
    "procHistReco.Draw('colz,text')\n",
    "canv.Print('procHistReco.pdf')\n",
    "prettyHist(catHistReco)\n",
    "catHistReco.Draw('colz,text')\n",
    "canv.Print('catHistReco.pdf')\n",
    "prettyHist(procHistPred)\n",
    "procHistPred.Draw('colz,text')\n",
    "canv.Print('procHistPred.pdf')\n",
    "prettyHist(catHistPred)\n",
    "catHistPred.Draw('colz,text')\n",
    "canv.Print('catHistPred.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw the bkg-prob distribution for each category\n",
    "bkgHists = {}\n",
    "sigHists = {}\n",
    "bkgProb = predProb[:,0]*(testY==0)\n",
    "for iProc in range(1, nClasses):\n",
    "    sigProb = predProb[:,0]*(testY==iProc) #could do this for inclusive signal? Or add other signal to background...\n",
    "    bkgHists[iProc] = r.TH1F('bkgProb_%s'%iProc, 'bkgProb_%s'%iProc, 50, 0., 1.)\n",
    "    sigHists[iProc] = r.TH1F('sigProb_%s'%iProc, 'sigProb_%s'%iProc, 50, 0., 1.)\n",
    "    for bkg,sig,w in zip(bkgProb,sigProb,testFW):\n",
    "        if bkg!=0: bkgHists[iProc].Fill(1.-bkg,w)\n",
    "        if sig!=0: sigHists[iProc].Fill(1.-sig,w)\n",
    "canv = r.TCanvas()\n",
    "for iProc in range(1, nClasses):\n",
    "    bkgInt = bkgHists[iProc].Integral()\n",
    "    bkgHists[iProc].Scale(1./bkgInt)\n",
    "    bkgHists[iProc].SetLineColor(r.kBlack)\n",
    "    sigInt = sigHists[iProc].Integral()\n",
    "    sigHists[iProc].Scale(1./sigInt)\n",
    "    sigHists[iProc].SetLineColor(r.kGreen+1)\n",
    "    sigHists[iProc].Draw('hist')\n",
    "    bkgHists[iProc].Draw('hist,same')\n",
    "    canv.Print('bkgProb_%s.pdf'%iProc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate (very) naive significance\n",
    "lumi = 77.\n",
    "for iProc in range(1, nClasses):\n",
    "    sigReco = lumi * sumwProcCatMapReco[(iProc,iProc)]\n",
    "    sigPred = lumi * sumwProcCatMapPred[(iProc,iProc)]\n",
    "    totReco = lumi * sumwCatMapReco[iProc]\n",
    "    totPred = lumi * sumwCatMapPred[iProc]\n",
    "    bkgReco = lumi * np.sum(testFW * (testY==0) * (pred==iProc) * (testM>123.) * (testM<127.) * (bkgProb<0.08))\n",
    "    bkgPred = lumi * np.sum(testFW * (testY==0) * (pred==iProc) * (testM>123.) * (testM<127.) * (bkgProb<0.08))\n",
    "    valReco = sigReco / np.sqrt(totReco+bkgReco)\n",
    "    valPred = sigPred / np.sqrt(totPred+bkgPred)\n",
    "    print 'for class %g the S and B counts are:'%iProc\n",
    "    print 'Reco: %1.3f and %1.3f,   BDT %1.3f and %1.3f'%(sigReco, totReco+bkgReco, sigPred, totPred+bkgPred)\n",
    "    print 'corresponding to naive significance of:'\n",
    "    print 'Reco: %1.3f,   BDT %1.3f \\n'%(valReco, valPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "xg.plot_importance(classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define rms function\n",
    "def getWidth(array):\n",
    "    sumW = np.sum(array)\n",
    "    mean = np.sum(array*testM)/ sumW\n",
    "    diff = testM - mean\n",
    "    diffSq = diff*diff\n",
    "    sumDiffSq = np.sum(diffSq*array) / sumW\n",
    "    width = np.sqrt(sumDiffSq)\n",
    "    return width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define approximate mean significance\n",
    "def getAMS(s, b, breg=1.):\n",
    "    b = b + breg\n",
    "    val = 0.\n",
    "    if b > 0.:\n",
    "        val = (s + b)*np.log(1. + (s/b))\n",
    "        val = 2*(val - s)\n",
    "        val = np.sqrt(val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going to try two different significance estimates - hopefully they agree well.. \n",
    "#first is to use only numpy, i.e. no ROOT, so a bit cruder bc no bkg fit and rms instead of effSigma\n",
    "lumi = 77.\n",
    "theProbs = 1. - predProb[:,0]\n",
    "\n",
    "#first do one category\n",
    "for iProc in range(1, nClasses):\n",
    "    bestCut = -1.\n",
    "    bestSignif = -1.\n",
    "    bestSig = -1.\n",
    "    bestBkg = -1.\n",
    "    #for cut in np.random.rand(100,1):\n",
    "    for cut in np.arange(0.9,1.0,0.0005):\n",
    "        sigArray = testFW * (testY==iProc) * (pred==iProc) * (theProbs>cut)\n",
    "        sigPred = lumi * 0.68 * np.sum( sigArray )\n",
    "        #sigRMS = getWidth(sigArray)\n",
    "        sigRMS = 0.67 * getWidth(sigArray) #ad hoc because rms seems to be an overestimate\n",
    "        #if cut < 0.9501 and cut > 0.9495: print 'sig RMS in proc %g is %1.3f'%(iProc,sigRMS)\n",
    "        totArray = testFW * (testY!=0) * (pred==iProc) * (theProbs>cut)\n",
    "        totPred = lumi * 0.68 * np.sum( totArray )\n",
    "        bkgArray = testFW * (testY==0) * (pred==iProc) * (testM>(125.-sigRMS)) * (testM<(125.+sigRMS)) * (theProbs>cut)\n",
    "        bkgPred = lumi * np.sum(bkgArray)\n",
    "        fullBkg = bkgPred + totPred - sigPred\n",
    "        valPred = getAMS(sigPred, fullBkg)\n",
    "        #print 'cut is %1.3f'%cut\n",
    "        #print 'rms is %1.2f'%sigRMS\n",
    "        #print 'S, B are %1.2f, %1.2f'%(sigPred,fullBkg)\n",
    "        #print 'signif is %1.2f'%valPred\n",
    "        if valPred > bestSignif: \n",
    "            bestCut = cut\n",
    "            bestSignif = valPred\n",
    "            bestSig = sigPred\n",
    "            bestBkg = fullBkg\n",
    "    print 'optimal one-category signifiance for proc %s:'%(iProc)\n",
    "    print 'cut = %1.3f, S = %1.2f, B = %1.2f, signif = %1.2f'%(bestCut, bestSig, bestBkg, bestSignif)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now try two categories\n",
    "for iProc in range(1, nClasses):\n",
    "    bestLoCut = -1.\n",
    "    bestHiCut = -1.\n",
    "    bestSignif = -1.\n",
    "    for cut1 in np.random.rand(50,1):\n",
    "        for cut2 in np.random.rand(50,1):\n",
    "            loCut = min(cut1, cut2)\n",
    "            hiCut = max(cut1, cut2)\n",
    "            #get significance of first (purest) cat\n",
    "            sigArray = testFW * (testY==iProc) * (pred==iProc) * (theProbs>hiCut)\n",
    "            sigPred = lumi * 0.68 * np.sum( sigArray )\n",
    "            sigRMS = getWidth(sigArray)\n",
    "            totArray = testFW * (testY!=0) * (pred==iProc) * (theProbs>hiCut)\n",
    "            totPred = lumi * 0.68 * np.sum( totArray )\n",
    "            bkgArray = testFW * (testY==0) * (pred==iProc) * (testM>(125.-sigRMS)) * (testM<(125.+sigRMS)) * (theProbs>hiCut)\n",
    "            bkgPred = lumi * np.sum(bkgArray)\n",
    "            fullBkg = bkgPred + totPred - sigPred\n",
    "            valPred_0 = getAMS(sigPred, fullBkg)\n",
    "            #get significance of second (purest) cat\n",
    "            sigArray = testFW * (testY==iProc) * (pred==iProc) * (theProbs>loCut) * (theProbs<hiCut)\n",
    "            sigPred = lumi * 0.68 * np.sum( sigArray )\n",
    "            sigRMS = getWidth(sigArray)\n",
    "            totArray = testFW * (testY!=0) * (pred==iProc) * (theProbs>loCut) * (theProbs<hiCut)\n",
    "            totPred = lumi * 0.68 * np.sum( totArray )\n",
    "            bkgArray = testFW * (testY==0) * (pred==iProc) * (testM>(125.-sigRMS)) * (testM<(125.+sigRMS)) * (theProbs>loCut) * (theProbs<hiCut)\n",
    "            bkgPred = lumi * np.sum(bkgArray)\n",
    "            fullBkg = bkgPred + totPred - sigPred\n",
    "            valPred_1 = np.getAMS(sigPred, fullBkg)\n",
    "            valPred = np.sqrt( valPred_0*valPred_0 + valPred_1*valPred_1)\n",
    "            if valPred > bestSignif: \n",
    "                bestLoCut = loCut\n",
    "                bestHiCut = hiCut\n",
    "                bestSignif = valPred\n",
    "    print 'optimal two-category signifiance for proc %s:'%(iProc)\n",
    "    print 'cutLow = %1.2f, cutHigh = %1.2f, signif = %1.2f'%(bestLoCut, bestHiCut, bestSignif)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now move on to the more \"traditional method\", which uses a fit to bkg distribution and full sigmaEff calc\n",
    "#set up 2D hists in diphoMass, bkgProb\n",
    "diagSigHists = {}\n",
    "fullSigHists = {}\n",
    "bkgOnlyHists = {}\n",
    "nBins = 100\n",
    "for iProc in range(1, nClasses):\n",
    "    diagSigHists[iProc] = r.TH2F('diagSigHist_%g'%iProc, 'diagSigHist_%g'%iProc, 10*nBins, 0., 1., nBins, 100., 180.)\n",
    "    fullSigHists[iProc] = r.TH2F('fullSigHist_%g'%iProc, 'fullSigHist_%g'%iProc, 10*nBins, 0., 1., nBins, 100., 180.)\n",
    "    bkgOnlyHists[iProc] = r.TH2F('bkgOnlyHist_%g'%iProc, 'bkgOnlyHist_%g'%iProc, 10*nBins, 0., 1., nBins, 100., 180.)\n",
    "    diagSigW = testFW * (testY==iProc) * (pred==iProc)\n",
    "    fullSigW = testFW * (testY!=0) * (pred==iProc)\n",
    "    bkgOnlyW = testFW * (testY==0) * (pred==iProc)\n",
    "    for mass,prob,diagW,fullW,bkgW in zip(testM,theProbs,diagSigW,fullSigW,bkgOnlyW):\n",
    "        diagSigHists[iProc].Fill(prob, mass, diagW)\n",
    "        fullSigHists[iProc].Fill(prob, mass, fullW)\n",
    "        bkgOnlyHists[iProc].Fill(prob, mass, bkgW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-category optimisation\n",
    "from diphoHelpers import evalSignif\n",
    "for iProc in range(1, nClasses):\n",
    "    bestCut = -1.\n",
    "    bestSignif = -1.\n",
    "    for cut in np.arange(0.9,1.0,0.001):\n",
    "        #print 'checking cut of %1.3f'%cut\n",
    "        signif = evalSignif( diagSigHists, fullSigHists, bkgOnlyHists, iProc, int(10*nBins*cut), 10*nBins, True )\n",
    "        #print 'its signif is %1.3f'%signif\n",
    "        if signif > bestSignif:\n",
    "            bestCut = cut\n",
    "            bestSignif = signif\n",
    "    print 'optimal one-category signifiance for proc %s:'%(iProc)\n",
    "    print 'cut = %1.3f, signif = %1.2f'%(bestCut, bestSignif)\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the background distributions look sensible\n",
    "checkHist = bkgOnlyHists[1].ProjectionY('tempProj', 900, 1000)\n",
    "#checkHist = bkgOnlyHists[1]\n",
    "canv = r.TCanvas()\n",
    "checkHist.Draw('hist')\n",
    "#checkHist.Draw('colz')\n",
    "canv.Print('checkHist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
